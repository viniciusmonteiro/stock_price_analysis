{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from random import sample \n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_key():\n",
    "    f = open(\"alpha_vantage_keyapi.txt\",\"r\")\n",
    "    return f.read()\n",
    "    \n",
    "\n",
    "def log(msg):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    f = open(\"crawler.log\",\"a+\")\n",
    "    return f.writelines(\"{0:%d-%m-%y %H:%M}. {1} \\n\".format(datetime.now(), msg))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_symbol(s):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    symbol = str(s.Symbol).split(\"/\")[0].strip()\n",
    "    symbol = symbol.replace(\"^\", \".\")\n",
    "    symbol += \"_{0}\".format(s.Market)\n",
    "    \n",
    "    return symbol\n",
    "\n",
    "\n",
    "def load_symbols(market):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the csv\n",
    "    df = pd.read_csv(\"watchlist-symbols.csv\",sep=\";\")\n",
    "    \n",
    "    # filter by market\n",
    "    if market != \"all\":\n",
    "        \n",
    "        # checking if the market in present in the watching list\n",
    "        if market not in df[\"Market\"].unique():\n",
    "            raise Exception('the specified market is not in the watchlist')\n",
    "        \n",
    "        df = df[df[\"Market\"]==market]\n",
    "    \n",
    "    # drop non\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # adapt the symbols for the api\n",
    "    lst_of_symbols = df.apply(lambda x: parse_symbol(x), axis=1).tolist()\n",
    "    \n",
    "    # take a sample for test\n",
    "    # lst_of_symbols = sample(lst_of_symbols,4)\n",
    "    \n",
    "    # exclude etfs\n",
    "    lst_tfs = [\"EXSH\"]\n",
    "    lst_of_symbols = [x for x in lst_of_symbols if x not in lst_tfs]\n",
    "    \n",
    "    return lst_of_symbols\n",
    "\n",
    "\n",
    "# for test\n",
    "# lst_of_symbols = load_symbols(\"MIL\")\n",
    "# print(len(lst_of_symbols), lst_of_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_data(ts_data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('ts_data.pickle', 'wb') as handle:\n",
    "        pickle.dump(ts_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return ts_data\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if Path(\"ts_data.pickle\").is_file():\n",
    "        with open('ts_data.pickle', 'rb') as handle:\n",
    "            ts_data = pickle.load(handle)\n",
    "    else:\n",
    "        ts_data = save_data({})\n",
    "    return ts_data\n",
    "        \n",
    "\n",
    "def query_api(symbol):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    market = symbol.split(\"_\")[1]\n",
    "    \n",
    "    if market in [\"NSY\", \"NDQ\"]:\n",
    "        # only ex: IBM\n",
    "        symbol = symbol.split(\"_\")[0]\n",
    "    else: \n",
    "        symbol = symbol.replace(\"_\", \".\")\n",
    "    \n",
    "    data, meta_data = ts.get_daily_adjusted(symbol=symbol, outputsize=\"compact\")\n",
    "    return data, meta_data\n",
    "\n",
    "\n",
    "def craw_data(market=\"all\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    lst_of_symbols = load_symbols(market)\n",
    "    for symbol in tqdm(lst_of_symbols):\n",
    "        try:\n",
    "            # wait\n",
    "            time.sleep(15)\n",
    "\n",
    "            # load the dict\n",
    "            ts_data = load_data()\n",
    "\n",
    "            # update the data\n",
    "            ts_data.update({symbol: query_api(symbol)})        \n",
    "            \n",
    "            # save the new data\n",
    "            save_data(ts_data)\n",
    "            \n",
    "            # log\n",
    "            log(\"successfully crawled: {0}\".format(symbol))\n",
    "        except Exception as e: \n",
    "            print(symbol, e)\n",
    "            log(\"error: {0} {1}\".format(symbol, e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "api_key = load_key()\n",
    "ts = TimeSeries(key=api_key, output_format='pandas', indexing_type='integer')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 32/95 [08:32<16:38, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAYN_XET Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 57/95 [15:07<09:59, 15.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEIA_EAM Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 74/95 [19:36<05:32, 15.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDS.A_NSY Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 75/95 [19:52<05:19, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR._LSE Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 76/95 [20:08<05:03, 15.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBS_LSE Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 86/95 [22:47<02:22, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ULVR_LSE Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 89/95 [23:35<01:36, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOW3_XET Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 94/95 [24:54<00:15, 15.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EZJ_LSE Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [25:10<00:00, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXSH_XET Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY_ADJUSTED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# callling the crawler manually \n",
    "runManual = True\n",
    "if runManual:\n",
    "    craw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job():\n",
    "    # Digits 0-6 represent the consecutive days of the week, starting from Monday.\n",
    "    weekdayno = datetime.today().weekday()\n",
    "    if weekno<5:\n",
    "        log(\"start crawler job.\")\n",
    "        craw_data()\n",
    "    \n",
    "    \n",
    "schedule.every().day.at(\"10:30\").do(job)\n",
    "schedule.every().day.at(\"12:30\").do(job)\n",
    "schedule.every().day.at(\"16:30\").do(job)\n",
    "schedule.every().day.at(\"20:30\").do(job)\n",
    "\n",
    "runSchedule = False\n",
    "while runSchedule:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['HER_MIL', 'SRG_MIL', 'FB_NDQ', 'DIS_NSY', 'QCOM_NDQ', 'MMM_NSY', 'EXPE_NDQ', 'XOM_NSY', 'BA_NSY', 'WFC_NSY', 'UCG_MIL', 'TIT_MIL', 'SPG_NSY', 'STM_MIL', 'RVLV_NSY', 'JNJ_NSY', 'ISP_MIL', 'IG_MIL', 'G_MIL', 'GRMN_NDQ', 'ENEL_MIL', 'DOV_MIL', 'BRK.B_NSY', 'BK_NSY', 'ATL_MIL', 'AAPL_NDQ', 'GOOGL_NDQ', 'ADBE_NDQ', 'T_NSY', 'A2A_MIL', 'BABA_NSY', 'AMRS_NDQ', 'ADS_NSY', 'BUD_NSY', 'AZM_MIL', 'BYND_NDQ', 'BKNG_NDQ', 'BPY_NDQ', 'SAM_NSY', 'BPYU_NDQ', 'CCL_NSY', 'CVX_NSY', 'KO_NSY', 'DOYU_NDQ', 'ENI_MIL', 'EQM_NSY', 'AIGE_MIL', 'ENB_NSY', 'EPD_NSY', 'ETH_MIL', 'FILA_MIL', 'FCA_MIL', 'GPS_NSY', 'HPQ_NSY', 'HUYA_NSY', 'HASI_NSY', 'HPE_NSY', 'HRL_NSY', 'IRC_MIL', 'IUKD_MIL', 'INTC_NDQ', 'MSFT_NDQ', 'NEXI_MIL', 'NNN_NSY', 'OXY_NSY', 'PIRC_MIL', 'PVH_NSY', 'PYPL_NDQ', 'PBR_NSY', 'PIA_MIL', 'REY_MIL', 'SNE_NSY', 'SRNE_NDQ', 'TSLA_NDQ', 'TM_NSY', 'TRIP_NDQ', 'UAA_NSY', 'UNH_NSY', 'ESPO_MIL', 'WM_NSY', 'WRK_NSY'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
